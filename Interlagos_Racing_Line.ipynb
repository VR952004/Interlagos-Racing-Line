{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1ImoN2md253ytB0mcjjRWIGp03a8iW-an",
      "authorship_tag": "ABX9TyMmI1wZUEM4mrYFFrj83rD0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VR952004/Interlagos-Racing-Line/blob/main/Interlagos_Racing_Line.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "i6dOBgtWUhUY"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.pipeline import Pipeline\n",
        "from tensorflow.keras import layers, models\n",
        "from sklearn.preprocessing import FunctionTransformer"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = '/content/drive/My Drive/Interlagos Racing Line/training_data/'\n",
        "test_data_path = '/content/drive/My Drive/Interlagos Racing Line/test_data/'"
      ],
      "metadata": {
        "id": "HWCHeYlObjBk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_frames_from_video(video_path, frame_interval=2):\n",
        "    \"\"\"\n",
        "    Extract frames from the video at a specified interval.\n",
        "\n",
        "    :param video_path: Path to the input video.\n",
        "    :param frame_interval: Interval at which to sample frames (e.g., every nth frame).\n",
        "    :return: A numpy array of extracted frames.\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames = []\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Cannot open video file {video_path}\")\n",
        "        return None\n",
        "\n",
        "    # Get the video's FPS and total number of frames\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    frame_count = 0\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # Extract only every nth frame, based on the frame_interval\n",
        "        if frame_count % frame_interval == 0:\n",
        "            frames.append(frame)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    cap.release()\n",
        "    frames = np.array(frames)\n",
        "    return frames"
      ],
      "metadata": {
        "id": "OJ-us_NhsjCE"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Preprocessing step: resize and normalize the frames\n",
        "def preprocess_frames(frames, frame_size=(224, 224)):\n",
        "    processed_frames = []\n",
        "    for frame in frames:\n",
        "        # Resize the frame\n",
        "        resized_frame = cv2.resize(frame, frame_size)\n",
        "\n",
        "        # Convert to grayscale\n",
        "        gray_frame = cv2.cvtColor(resized_frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "        # Normalize the frame\n",
        "        normalized_frame = gray_frame / 255.0\n",
        "\n",
        "        # Reshape and append the frame\n",
        "        processed_frames.append(normalized_frame.reshape(*frame_size, 1))\n",
        "\n",
        "    return np.array(processed_frames)"
      ],
      "metadata": {
        "id": "6mJ0a7YckSxD"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using FunctionTransformer to turn the preprocessing into a pipeline step\n",
        "extract_frames_transformer = FunctionTransformer(extract_frames_from_video)\n",
        "preprocess_transformer = FunctionTransformer(preprocess_frames, kw_args={\"frame_size\": (224, 224)})"
      ],
      "metadata": {
        "id": "mB0p8WhtsyEU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Define the Autoencoder model structure\n",
        "def build_autoencoder(input_shape=(224, 224, 1)):\n",
        "    input_img = layers.Input(shape=input_shape)\n",
        "\n",
        "    # Encoder\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    latent_space = layers.MaxPooling2D((2, 2), padding='same')(x)\n",
        "\n",
        "    # Decoder\n",
        "    x = layers.Conv2D(128, (3, 3), activation='relu', padding='same')(latent_space)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "    x = layers.Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = layers.UpSampling2D((2, 2))(x)\n",
        "\n",
        "    # Output layer\n",
        "    decoded = layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
        "\n",
        "    # Compile the model\n",
        "    autoencoder = models.Model(input_img, decoded)\n",
        "    autoencoder.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "    return autoencoder"
      ],
      "metadata": {
        "id": "zmplpYxlkjKy"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the autoencoder model\n",
        "autoencoder = build_autoencoder()"
      ],
      "metadata": {
        "id": "e54l6Kf9tU4a"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Custom wrapper for the autoencoder\n",
        "class AutoencoderWrapper:\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Fit the autoencoder on the data\n",
        "        self.model.fit(X, X, epochs=10, batch_size=256, validation_split=0.2)\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Use the autoencoder to reconstruct the frames\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# Build the full pipeline: extract frames -> preprocess frames -> autoencoder\n",
        "pipeline = Pipeline(steps=[\n",
        "    ('extract_frames', extract_frames_transformer),\n",
        "    ('preprocess_frames', preprocess_transformer),\n",
        "    ('autoencoder', AutoencoderWrapper(autoencoder))\n",
        "])"
      ],
      "metadata": {
        "id": "qJwhbyaPnaBc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Process all videos in the training_data folder\n",
        "all_frames = []\n",
        "\n",
        "# Iterate over all video files in the training_data folder\n",
        "for video_file in os.listdir(train_data_path):\n",
        "    video_path = os.path.join(train_data_path, video_file)\n",
        "\n",
        "    # Run the pipeline to extract, preprocess, and store frames\n",
        "    print(f\"Processing {video_file}\")\n",
        "    frames = pipeline.named_steps['extract_frames'].transform(video_path)\n",
        "    processed_frames = pipeline.named_steps['preprocess_frames'].transform(frames)\n",
        "\n",
        "    # If frames were processed successfully, add them to all_frames\n",
        "    if processed_frames is not None:\n",
        "        all_frames.append(processed_frames)\n",
        "\n",
        "# Combine all frames from all videos into one NumPy array\n",
        "train_frames = np.concatenate(all_frames, axis=0)\n",
        "print(f\"Total training frames: {train_frames.shape[0]}\")\n",
        "\n",
        "# Step 5: Train the autoencoder using the processed frames\n",
        "pipeline.named_steps['autoencoder'].fit(train_frames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZlwPF-Qnqi4",
        "outputId": "1a68fc36-baf2-4426-aae0-63fcd7e8e3d8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing processed_onboard1.mp4\n",
            "Processing processed_onboard2.mp4\n",
            "Processing processed_onboard3.mp4\n",
            "Processing processed_onboard4.mp4\n",
            "Processing processed_onboard5.mp4\n",
            "Processing processed_onboard6.mp4\n",
            "Processing processed_onboard7.mp4\n",
            "Processing processed_onboard8.mp4\n",
            "Processing processed_onboard9.mp4\n",
            "Total training frames: 26019\n",
            "Epoch 1/10\n",
            "82/82 [==============================] - 846s 10s/step - loss: 0.0105 - val_loss: 0.0027\n",
            "Epoch 2/10\n",
            "82/82 [==============================] - 837s 10s/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 3/10\n",
            "82/82 [==============================] - 841s 10s/step - loss: 0.0021 - val_loss: 0.0013\n",
            "Epoch 4/10\n",
            "82/82 [==============================] - 843s 10s/step - loss: 0.0018 - val_loss: 0.0013\n",
            "Epoch 5/10\n",
            "82/82 [==============================] - 847s 10s/step - loss: 0.0015 - val_loss: 0.0010\n",
            "Epoch 6/10\n",
            "82/82 [==============================] - 847s 10s/step - loss: 0.0014 - val_loss: 9.6508e-04\n",
            "Epoch 7/10\n",
            "82/82 [==============================] - 849s 10s/step - loss: 0.0013 - val_loss: 9.7704e-04\n",
            "Epoch 8/10\n",
            "82/82 [==============================] - 848s 10s/step - loss: 0.0012 - val_loss: 8.5051e-04\n",
            "Epoch 9/10\n",
            "82/82 [==============================] - 851s 10s/step - loss: 0.0011 - val_loss: 7.3917e-04\n",
            "Epoch 10/10\n",
            "82/82 [==============================] - 860s 10s/step - loss: 9.8751e-04 - val_loss: 6.8105e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.AutoencoderWrapper at 0x7db5ed454730>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Save the entire pipeline (preprocessing + autoencoder)\n",
        "pipeline_file = '/content/drive/My Drive/Interlagos Racing Line/racingline_complete_pipeline.pkl'\n",
        "joblib.dump(pipeline, pipeline_file)\n",
        "\n",
        "print(f\"Complete pipeline saved to {pipeline_file}\")"
      ],
      "metadata": {
        "id": "7uR3GFpXuJM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fef176a-0476-4a34-8f49-75f52bcac92b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complete pipeline saved to /content/drive/My Drive/Interlagos Racing Line/racingline_complete_pipeline.pkl\n"
          ]
        }
      ]
    }
  ]
}